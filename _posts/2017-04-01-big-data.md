---
layout:     post
title:      "BigData框架选型"
subtitle:   "该篇文章主要讲述以Spark分布式计算框架为中心，对周围大数据框架的选型。"
date:       2017-04-01 12:30:00
author:     "ryan"
header-img: "img/post-bg-06.jpg"
---

# 1. Spark介绍

Spark是一个可以用来快速实现分布式集群计算的平台。和Hadoop的MapReduce是一个类型的东西，但他们最大的区别就是Spark比MapReduce更快(如下图)。现在都属于apache基金会的开源产品。

![2017-04-11-spark-mapreduce](//ryanwli.github.io/img/2017/2017-04-11-spark-mapreduce.png)

存储设备：内存(10GB/s) > SSD(600MB/s) > HDD(100MB/s)

Spark的中间计算结果使用了内存来存储，而Mapreduce每次都会讲中间结果存储到硬盘上面，如果中间计算特别多，Spark的分布式计算性能是指数倍的增加的。但这里也引入了一个问题，Spark比Mapreduce更加的占用服务器的内存资源。

Spark使用”驱动程序“来创建一系列的RDD(SPARK核心，弹性分布式数据集)，生成DGA图(有向无环图，就是一堆的转换RDD和执行RDD)，并启动若干(可配置)”执行节点“来，将DGA传递给这些执行节点来执行分布式计算，如下图：

![2017-04-11-spark-rdd](//ryanwli.github.io/img/2017/2017-04-11-spark-rdd.jpg)

从数据的输入，生成2个执行节点，分别在两个执行节点生成A和C的输入RDD，然后再进行分别的B和D的转换RDD，然后汇总到驱动节点E的RDD，然后F的RDD输出。整个流程是惰性的，只有真正有执行类型的RDD才会真正执行前面输入到E的RDD这一系列的转换；

后面，我们会专门开一篇文章来详细的讲解Spark工作原理，以及如何使用的；



# 2. Spark与Hadoop

## 2.1 Spark与Yarn

上面说了 Spark和Hadoop中Mapreduce的最大区别，Spark同Mapreduce一样会依赖一些Hadoop中其他产品，Spark可以用Hadoop Yarn来做集群的管理。不过Spark也可以不基于Yarn，它有自己独立的集群管理器，如果服务器上只有Spark应用完全可以使用独立集群，但是服务器上不光运行Spark应用，还有其他应用如hdfs之类的，那么就需要使用Yarn来做所有应用的集群管理；

## 2.2 Spark与Hdfs

Spark没有自己的存储模块，它在做分布式计算的时候还是需要依赖其他的存储模块来进行数据的导入和导出。

### 2.2.1 Hdfs介绍

最早Google公司提出了《Google File System》，介绍了如何使用廉价的服务器集群来分布式的存储大量的数据的理论，有了这个理论，后来衍生出了开源的Hdfs(Hadoop Distributed File System)，大致原理如下图：

![2017-04-11-hdfs](//ryanwli.github.io/img/2017/2017-04-11-hdfs.png)

Hdfs和传统类Unix的操作系统的文件存储方式大致一样的，最大的不同就是Hdfs是分布式的。一个文件的不同部分可以存储到不同的机器磁盘上面。

上图中的NameNode和DataNode是主从的关系，一个NameNode对应N个DataNode。NameNode中储文件的名称，以及对应到集群中不同位置的Block，可以理解为传统文件系统的Block，不过在Hdfs中的这个Block很大，默认是64MB，一般传统文件系统在4KB左右。从图中可以看出data1.txt有3个Block，分别在DataNode1,2,3,4,5都有存储，而且重复的，为什么会重复，是因为Hdfs内部做了高可用性的处理，将同一个Block复制到其他DataNode节点做了备份，所以会看见有很多重复的。

Spark在读入Hdfs文件的时候，会根据该Hdfs文件的Block数来开启分区数量，然后根据配置的执行节点数，将这些分区放到执行节点中执行，意思就是说，每一个Block会在一个分区执行提交到Spark一系列的RDD操作；

### 2.2.2 Hdfs局限性

Hdfs一般用在一次性处理的数据规模都比较大，所以Hdfs一般是以文件流的形式进行访问和写入，注重流方式的处理吞吐量，访问速度是排在第二位的，也不支持随机检索。

Hdfs为了实现高效的分布式文件存取，简化了一致性模型，它只能创建和追加内容到文件，以及删除文件，并不能修改已有文件的内容。

所以hdfs并不适用于大数据平台下游端应用对数据查询和修改的要求(如：网站，移动端API，后端业务系统的使用)，hdfs只适用于上游端大文件大数据的存储和读取处理(如：用户行为数据，Nginx访问日志等等)；正因为这个，所以我们引入了MongoDB来做下游数据的分布式存储，当然Hadoop家族里面也有类似产品HBase，以及Apache的Cassandra。

后面，也会单独开一个章节来介绍Hdfs工作原理，以及如何使用；



# 3. Spark与MongoDB

### 3.1 什么选用MongoDB

对于我们公司来说，已有一些系统基于MongoDB在使用了，对于它的了解也是比较熟悉的，比较不容踩坑；对于前期下游数据不大，完全可以和已有系统公用MongoDB集群，来节省服务器的开销；

另外，MongoDB在大数据这一领域已经有这些公司有成功案例：

|                                   | MongoDB                                  | Hadoop                                   |
| --------------------------------- | ---------------------------------------- | ---------------------------------------- |
| Ebay                              | User data and metadata management for product catalog | User analysis for personalized search & recommendations |
| Orbitz                            | Management of hotel data and pricing     | Hotel segmentation to support building search facets |
| Pearson                           | Student identity and access control. Content management of course materials | Student analytics to create adaptive learning programs |
| Foursquare                        | User data, check-ins, reviews, venue content management | User analysis, segmentation and personalization |
| Tier 1 Investment Bank            | Tick data, quants analysis, reference data distribution | Risk modeling, security and fraud detection |
| Industrial Machinery Manufacturer | Storage and real-time analytics of sensor data collected from connected vehicles | Preventive maintenance programs for fleet optimization. In-field monitoring of vehicle components for design enhancements |
| SFR                               | Customer service applications accessed via online portals and call centers | Analysis of customer usage, devices & pricing to optimize plans |
| Prescient                         | Correlates threat data with traveler locations for real-time alerting | Analyzes streams of threat data from social media, press agencies |



### 3.2 与Spark集成介绍

MongoDB提供了一个Connector for Hadoop的插件，使用这个插件可以让Spark读写MongoDB，派生Hadoop Mapreduce的InputFormat和OutpuFormat。同时该插件很好的支持了MongoDB Split分批读取，以及MongoDB  Cluster部署下的分批读取，Split分批读取，分批Key是_id(该ID是Mongodb默认的，并且必须存在的); 分批数就等于Spark RDD的分区数，这样就可以快速高效的读取Mongo Cluster集群数据，并行快速计算；

后面，会在Spark那篇文章详细贴出代码如何使用。



# 4. Spark与Kafka

Spark支持流式处理，其中Spark流式处理的核心组件是Spark-Streaming，它可以实现实时处理，每次可以按照一定频次接受流中数据(比如，1s或者60s一个间隙)并生成RDD数据处理集，然后执行分布式计算，并输出到相关存储介质中如Hdfs，HBase, Mongodb等；

Spark需要与Kafka集成，需要在Spark-Streaming基础上，附加一个Spark-Stream-Kafka的组件，来接受消息队列的数据流；

Kafka可以实现一个队列多个消费者并行消费，在并行消费的基础上还执行消息的顺序性；

Kafka支持Cluster，一个消息队列的消息可以存储在不同的Broker中(可以理解为Cluster中的Node)，就算集群，Kafka也支持消息的顺序性；

Kafka比一般其他的MQ速度更快，其原因是它的消息消费后不是删除，而是在Zookeeper保存了一个数据使用偏移位，删除的动作，放到了后台JOB来执行过期消息的删除；

上面的这些特性，让它成为了Spark做实时大数据分析第一搭档。看下面的图，我尝试来解释一下Kafka的原理：

![2017-04-11-kafka](//ryanwli.github.io/img/2017/2017-04-11-kafka.png)

一个消息队列在Kafka里面叫Topic，一个Topic可能将消息按照指定Key，Hash后的值放到不同的分区，这些分区有在不同的Kafka  Broker中，Spark会启动多个“执行节点”来接受该Topic的消息，如果存在Key的消息，Kafka会把同一个Key消息一直发给同一个Spark的“执行节点”来进行消费，这样它就能保证同一个Key的消息是顺序。倘若没有Key，他会随机的将消息发送给Spark的任意“执行节点”来进行消费。注意下面的Old->New，Kafka的消息是在末尾段，就是NEW那端追加的，然后移动Zookeeper中的消息使用位的偏移量，来执行新消息的读取，然后就定时删除Old那端过期的消息。这样追加消息是磁盘顺序操作，删除也是后台操作，这样就尽可能的增加的消息的处理速度；



# 5. 架构选型

### 5.1 第一期

![2017-04-11-phase1](//ryanwli.github.io/img/2017/2017-04-11-phase1.png)



### 5.2 第二期



![2017-04-11-phase2](//ryanwli.github.io/img/2017/2017-04-11-phase2.png)